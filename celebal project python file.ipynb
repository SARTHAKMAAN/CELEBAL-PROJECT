{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5364f7-2873-4a86-a181-9cac52282a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, count, sum, mean, stddev, isnan, isnull\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d7b71c9-1d67-444e-b86e-d97c2c27a7ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----------+------------+--------+-----------------+\n|TransactionID|Customer ID|Product ID|Total Amount| Channel|MarketingCampaign|\n+-------------+-----------+----------+------------+--------+-----------------+\n|            1|        101|       501|         500|     Web|       Campaign A|\n|            2|        102|       502|         300|  Mobile|       Campaign B|\n|            3|        103|       501|         700|In-Store|       Campaign A|\n+-------------+-----------+----------+------------+--------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Load the table into a DataFrame\n",
    "transactions_df = spark.table(\"transaction\")\n",
    "\n",
    "# Preview it\n",
    "transactions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466b575c-28ce-400d-861d-9b2a4af53d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------------+-----+\n|ProductID|Product Name|       Category|Price|\n+---------+------------+---------------+-----+\n|      501|  Smartphone|    Electronics| 1000|\n|      502|     Shampoo|  Personal Care|  300|\n|      503|     Blender|Home Appliances|  500|\n|      504|  Headphones|    Electronics|  800|\n+---------+------------+---------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "products_df = spark.table(\"products\")\n",
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d6e7deb-f8ee-430a-812a-62fc7706c3dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----------+------------+--------+-----------------+------------+-------------+-----+\n|TransactionID|Customer ID|Product ID|Total Amount| Channel|MarketingCampaign|Product Name|     Category|Price|\n+-------------+-----------+----------+------------+--------+-----------------+------------+-------------+-----+\n|            3|        103|       501|         700|In-Store|       Campaign A|  Smartphone|  Electronics| 1000|\n|            2|        102|       502|         300|  Mobile|       Campaign B|     Shampoo|Personal Care|  300|\n|            1|        101|       501|         500|     Web|       Campaign A|  Smartphone|  Electronics| 1000|\n+-------------+-----------+----------+------------+--------+-----------------+------------+-------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Join on Product ID (with different column names)\n",
    "combined_df = transactions_df.join(\n",
    "    products_df,\n",
    "    transactions_df[\"`Product ID`\"] == products_df[\"ProductID\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Drop duplicate join column if needed\n",
    "combined_df = combined_df.drop(products_df[\"ProductID\"])\n",
    "\n",
    "# Show joined data\n",
    "combined_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2c2a61e-4983-4ddf-a833-431a6fa5fc42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Customer ID</th><th>AvgOrderValue</th></tr></thead><tbody><tr><td>101</td><td>1000.0</td></tr><tr><td>102</td><td>300.0</td></tr><tr><td>103</td><td>1000.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         101,
         1000.0
        ],
        [
         102,
         300.0
        ],
        [
         103,
         1000.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Customer ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "AvgOrderValue",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, sum\n",
    "\n",
    "# Add price to each transaction\n",
    "enriched_df = combined_df.withColumn(\"OrderValue\", combined_df[\"Price\"])\n",
    "\n",
    "# Group by customer\n",
    "avg_order_value = enriched_df.groupBy(\"Customer ID\").agg(avg(\"OrderValue\").alias(\"AvgOrderValue\"))\n",
    "display(avg_order_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df8f0762-6bf6-4a4c-97d3-7f8bd1d035f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+\n|Product ID|Product Name|TotalOrders|\n+----------+------------+-----------+\n|       501|  Smartphone|          2|\n|       502|     Shampoo|          1|\n+----------+------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#most popular product\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "popular_products = combined_df.groupBy(\"Product ID\", \"Product Name\").agg(count(\"*\").alias(\"TotalOrders\")).orderBy(\"TotalOrders\", ascending=False)\n",
    "popular_products.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c12565dc-486c-494a-b6bd-6a22a671a07e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n|     Category|TotalOrders|\n+-------------+-----------+\n|  Electronics|          2|\n|Personal Care|          1|\n+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#popular categories\n",
    "popular_categories = combined_df.groupBy(\"Category\").agg(count(\"*\").alias(\"TotalOrders\")).orderBy(\"TotalOrders\", ascending=False)\n",
    "popular_categories.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea6c5588-830d-4f89-89da-3f0234161afa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import re\n",
    "\n",
    "# Function to clean column names because they cant have any space ex- customer id = customer_id\n",
    "def clean_column_names(df):\n",
    "    for old_name in df.columns:\n",
    "        new_name = re.sub(r'[^a-zA-Z0-9_]', '_', old_name)  # Replace space/special characters with \"_\"\n",
    "        df = df.withColumnRenamed(old_name, new_name)\n",
    "    return df\n",
    "\n",
    "# Apply cleaning\n",
    "clean_df = clean_column_names(combined_df)\n",
    "\n",
    "# saving \n",
    "clean_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"combined_transaction_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae3dde44-f53f-4794-b1d3-85574a891ed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,recompressionCodec:string,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,isFull:boolean,approxClusteringQuality:double,approxClusteringQualityPerColumn:array<double>,approxClusteringCoverage:double,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numIdealFilesWithTrimmedStringMaxValue:bigint,numAddedFilesWithSameMinMaxOnClusteringColumns:array<bigint>,numClusteringTasksPlanned:int,numCompactionTasksPlanned:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numIntermediateNodesCompacted:bigint,totalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize using Delta features\n",
    "spark.sql(\"OPTIMIZE combined_transaction_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b984086-1ec3-4d54-b205-affaea6d4fc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----------+------------+-------+-----------------+------------+--------+-----+\n|TransactionID|Customer ID|Product ID|Total Amount|Channel|MarketingCampaign|Product Name|Category|Price|\n+-------------+-----------+----------+------------+-------+-----------------+------------+--------+-----+\n|            0|          0|         0|           0|      0|                0|           0|       0|    0|\n+-------------+-----------+----------+------------+-------+-----------------+------------+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# monitor data quality\n",
    "\n",
    "from pyspark.sql.types import NumericType\n",
    "from pyspark.sql.functions import col, when, count, isnan, isnull\n",
    "\n",
    "# Separate numeric columns for isnan()\n",
    "numeric_cols = [f.name for f in combined_df.schema.fields if isinstance(f.dataType, NumericType)]\n",
    "\n",
    "# Combine isnull + isnan for numeric, only isnull for others\n",
    "null_counts = combined_df.select([\n",
    "    count(when(isnull(c) | (isnan(c) if c in numeric_cols else False), c)).alias(c)\n",
    "    for c in combined_df.columns\n",
    "])\n",
    "\n",
    "null_counts.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "celebal project",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}